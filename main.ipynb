{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": false,
    "_uuid": "4b203aefd23f0d4acdeb0dad0df3e1833f25fff7",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$RECYCLE.BIN', '$WinREAgent', 'apache-jena-fuseki-4.3.2', 'Documents and Settings', 'DumpStack.log.tmp', 'EUMONBMP.SYS', 'hiberfil.sys', 'Intel', 'OneDriveTemp', 'pagefile.sys', 'PerfLogs', 'Program Files', 'Program Files (x86)', 'ProgramData', 'Project.log', 'Python', 'Python310', 'Recovery', 'swapfile.sys', 'System Volume Information', 'Users', 'Windows']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package subjectivity to\n",
      "[nltk_data]     C:\\Users\\adria\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package subjectivity is already up-to-date!\n",
      "[nltk_data] Error loading lexicon: Package 'lexicon' not found in\n",
      "[nltk_data]     index\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "\n",
    "#2. Import os\n",
    "#Make the input data files available in the computer directory.\n",
    "#In this case, running this will list the files\n",
    "\n",
    "import os\n",
    "print(os.listdir(\"/\"))\n",
    "nltk.download('subjectivity')\n",
    "nltk.download('lexicon')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "0e5edc639dc39994cecf7b0dfa70a019c595955e",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. Make the creation of data in subjective and objective point of view of the sentences.\n",
    "#Read 100 obj phases and 100 subj phases.\n",
    "\n",
    "n_instances = 100\n",
    "subjective_docs = [(sent, 'subj') for sent in subjectivity.sents(categories='subj')[:n_instances]]\n",
    "objective_docs = [(sent, 'obj') for sent in subjectivity.sents(categories='obj')[:n_instances]]\n",
    "len(subjective_docs), len(objective_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "5ed8790ab8d6a0c9cb74554f34bde3d7afd16a73",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['the',\n",
       "  'movie',\n",
       "  'begins',\n",
       "  'in',\n",
       "  'the',\n",
       "  'past',\n",
       "  'where',\n",
       "  'a',\n",
       "  'young',\n",
       "  'boy',\n",
       "  'named',\n",
       "  'sam',\n",
       "  'attempts',\n",
       "  'to',\n",
       "  'save',\n",
       "  'celebi',\n",
       "  'from',\n",
       "  'a',\n",
       "  'hunter',\n",
       "  '.'],\n",
       " 'obj')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4.Deviding the 2 kinds of sentences to maintain an evenly balanced distribution.\n",
    "subjective_docs[0]\n",
    "objective_docs[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "f0131d15ee005d8a685361108a803b69a5ffc763",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_subjective_docs = subjective_docs[:80]\n",
    "test_subjective_docs = subjective_docs[80:100]\n",
    "train_objective_docs = objective_docs[:80]\n",
    "test_objective_docs = objective_docs[80:100]\n",
    "training_docs = train_subjective_docs+train_objective_docs\n",
    "testing_docs = test_subjective_docs+test_objective_docs\n",
    "\n",
    "sentim_analyzer = SentimentAnalyzer()\n",
    "total_neg_words = sentim_analyzer.all_words([mark_negation(doc) for doc in training_docs])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "bbea6aa7a48e740d2f581a9c2d975579ed9a9395",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#5. I created unigrams for then the simple strokes of the words that are used, managing the negation.\n",
    "#For unigram we will have 3 characteristics and all 3 are independent of each other.\n",
    "\n",
    "#\n",
    "unigram_feats = sentim_analyzer.unigram_word_feats(total_neg_words, min_freq=4)\n",
    "len(unigram_feats)\n",
    "\n",
    "sentim_analyzer.add_feat_extractor(extract_unigram_feats, unigrams=unigram_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "d2b3af74241f9ef8fce7bb5ce854f7db7af2bf2e",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#6.We are ready to train our classifier on the training set and generate the #assessment results:\n",
    "#Training classify\n",
    "\n",
    "training_set = sentim_analyzer.apply_features(training_docs)\n",
    "test_set = sentim_analyzer.apply_features(testing_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "bdd59eaeab2e5ba8c9ea2b2094d70da3f614fb8b",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier\n"
     ]
    }
   ],
   "source": [
    "trainer = NaiveBayesClassifier.train\n",
    "classifier = sentim_analyzer.train(trainer, training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "5e55e416ec3fe049805f8b99802e2625ef3c1303",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "d84c4835ec213b4954f8486daf7151eee5eb5572",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#7. Test Phrase List Definition\n",
    "#Manipulate paragraphs\n",
    "\n",
    "sentences = [\"Brad Pitt is smart, handsome, and funny!\", #  positive phrases example\n",
    "             \"The movie was good.\",\n",
    "             \"The movie was kind of good.\"\n",
    "             \"However, Johnny Depp is charming \",\n",
    "             \"At least it isn't a horrible movie.\",\n",
    "             \"Action movies with Angelina has never been this good like this one.\",\n",
    "             \":) and :D\"\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "03fac0e8aa4d93d0b40276823864b5125a04637d",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "more_sentences = [\n",
    "    \"Interstellar est imposant, mais il n'est pas impressionnant. \", # negative phrases example\n",
    "    \"The plot was good, but the characters are uncompelling and the dialog is not great.\",\n",
    "    \"Most cartoons movies are childish.\",\n",
    "    \"A really bad, horrible book.\",\n",
    "    \"Drama has never been good.\",\n",
    "    \":( \"\n",
    " ]\n",
    "\n",
    "sentences.extend(more_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "2e1f145c46cc70b5f5788062a79485072bda853f",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "paragraph = \"It was one of the worst movies I've seen, despite good reviews. \\\n",
    " Unbelievably bad acting!! Poor direction. VERY poor production. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "1ee0c73c147f43033765b29dc14faf56867da334",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "lines_list = tokenize.sent_tokenize(paragraph)\n",
    "sentences.extend(lines_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "7213cfba95a1935e945323e74e208ca41d756a8f",
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brad Pitt is smart, handsome, and funny!\n",
      "compound: 0.8439, neg: 0.0, neu: 0.306, pos: 0.694, \n",
      "The movie was good.\n",
      "compound: 0.4404, neg: 0.0, neu: 0.508, pos: 0.492, \n",
      "The movie was kind of good.However, Johnny Depp is charming \n",
      "compound: 0.5859, neg: 0.0, neu: 0.703, pos: 0.297, \n",
      "At least it isn't a horrible movie.\n",
      "compound: 0.431, neg: 0.0, neu: 0.637, pos: 0.363, \n",
      "Action movies with Angelina has never been this good like this one.\n",
      "compound: 0.7073, neg: 0.0, neu: 0.63, pos: 0.37, \n",
      ":) and :D\n",
      "compound: 0.7925, neg: 0.0, neu: 0.124, pos: 0.876, \n",
      "Interstellar est imposant, mais il n'est pas impressionnant. \n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "The plot was good, but the characters are uncompelling and the dialog is not great.\n",
      "compound: -0.7042, neg: 0.327, neu: 0.579, pos: 0.094, \n",
      "Most cartoons movies are childish.\n",
      "compound: -0.296, neg: 0.355, neu: 0.645, pos: 0.0, \n",
      "A really bad, horrible book.\n",
      "compound: -0.8211, neg: 0.791, neu: 0.209, pos: 0.0, \n",
      "Drama has never been good.\n",
      "compound: -0.3412, neg: 0.376, neu: 0.624, pos: 0.0, \n",
      ":( \n",
      "compound: -0.4404, neg: 1.0, neu: 0.0, pos: 0.0, \n",
      "It was one of the worst movies I've seen, despite good reviews.\n",
      "compound: -0.7584, neg: 0.394, neu: 0.606, pos: 0.0, \n",
      "Unbelievably bad acting!!\n",
      "compound: -0.6572, neg: 0.686, neu: 0.314, pos: 0.0, \n",
      "Poor direction.\n",
      "compound: -0.4767, neg: 0.756, neu: 0.244, pos: 0.0, \n",
      "VERY poor production.\n",
      "compound: -0.6281, neg: 0.674, neu: 0.326, pos: 0.0, \n"
     ]
    }
   ],
   "source": [
    "total = SentimentIntensityAnalyzer()\n",
    "for sentence in sentences:\n",
    "     print(sentence)\n",
    "     loading = total.polarity_scores(sentence)\n",
    "     for k in sorted(loading):\n",
    "         print('{0}: {1}, '.format(k, loading[k]), end='')\n",
    "     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
